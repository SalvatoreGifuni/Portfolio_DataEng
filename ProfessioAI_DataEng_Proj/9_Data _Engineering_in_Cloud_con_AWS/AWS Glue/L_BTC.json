{
	"jobConfig": {
		"name": "L_BTC",
		"description": "",
		"role": "arn:aws:iam::575108947083:role/Glue-role",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "L_BTC.py",
		"scriptLocation": "s3://aws-glue-assets-575108947083-eu-north-1/scripts/",
		"language": "python-3",
		"spark": false,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-10-15T17:44:57.868Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-575108947083-eu-north-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-575108947083-eu-north-1/sparkHistoryLogs/",
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nfrom awsglue.dynamicframe import DynamicFrame\r\nfrom datetime import datetime\r\n\r\ndef convert_types(rec):\r\n    # Convert the 'data' field from string to date\r\n    rec['data'] = datetime.strptime(rec['data'], '%Y-%m-%d').date()\r\n    # Convert the 'prezzo' field to float\r\n    rec['prezzo'] = float(rec['prezzo'])\r\n    # Convert the 'indice_google_trend' field to int\r\n    rec['indice_google_trend'] = int(rec['indice_google_trend'])\r\n    return rec\r\n\r\n# Retrieve the job name from the job parameters\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# Read Parquet data from S3\r\ndatasource = glueContext.create_dynamic_frame.from_options(\r\n    connection_type=\"s3\",\r\n    connection_options={\"paths\": [\"s3://s3-sg-bucket-gold/BTC\"]},\r\n    format=\"parquet\"\r\n)\r\n\r\n# Apply the transformation to convert data types\r\nconverted_datasource = Map.apply(frame=datasource, f=convert_types)\r\n\r\n# Apply mapping to ensure correct data types\r\nmapped_datasource = ApplyMapping.apply(\r\n    frame=converted_datasource,\r\n    mappings=[\r\n        (\"data\", \"date\", \"data\", \"date\"),\r\n        (\"prezzo\", \"double\", \"prezzo\", \"double\"),\r\n        (\"indice_google_trend\", \"int\", \"indice_google_trend\", \"int\")\r\n    ]\r\n)\r\n\r\n# Write the DynamicFrame to Redshift Serverless using the cataloged connection\r\nglueContext.write_dynamic_frame.from_jdbc_conf(\r\n    frame=mapped_datasource,\r\n    catalog_connection=\"my_redshift_connection\",\r\n    connection_options={\"dbtable\": \"my_btc\", \"database\": \"dev\"},\r\n    redshift_tmp_dir=\"s3://sg-temporary-dir/BTC/\"\r\n)\r\n\r\n# Commit the job to mark it as complete\r\njob.commit()"
}