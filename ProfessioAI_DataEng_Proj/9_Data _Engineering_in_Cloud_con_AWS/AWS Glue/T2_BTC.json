{
	"jobConfig": {
		"name": "T2_BTC",
		"description": "",
		"role": "arn:aws:iam::575108947083:role/Glue-role",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "T2_BTC.py",
		"scriptLocation": "s3://aws-glue-assets-575108947083-eu-north-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-10-14T10:44:12.663Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-575108947083-eu-north-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-575108947083-eu-north-1/sparkHistoryLogs/",
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nfrom pyspark.sql.functions import avg, col, round\r\nfrom pyspark.sql.window import Window\r\nfrom pyspark.sql.types import DecimalType\r\n\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# Read cleaned data from the silver bucket\r\ndf = glueContext.create_dynamic_frame.from_options(\r\n    connection_type=\"s3\",\r\n    connection_options={\"paths\": [\"s3://s3-sg-bucket-silver/BTC\"]},\r\n    format=\"parquet\"\r\n).toDF()\r\n\r\n# Calculate the 10-day moving average\r\nwindowSpec = Window.orderBy(\"Date\").rowsBetween(-9, 0)\r\ndf = df.withColumn('Price_MA_10', avg('Price').over(windowSpec))\r\n\r\n# Calculate the weekly average price\r\ndf = df.groupBy('Date').agg(\r\n    avg('Price_MA_10').alias('Weekly_Price_MA')\r\n)\r\n\r\n# Read Google Trends data from the raw bucket\r\ntrend_df = glueContext.create_dynamic_frame.from_options(\r\n    connection_type=\"s3\",\r\n    connection_options={\"paths\": [\"s3://s3-sg-bucket-raw/BTC/google_trend_bitcoin.csv\"]},\r\n    format=\"csv\",\r\n    format_options={\"withHeader\": True}\r\n).toDF()\r\n\r\n# Merge the datasets based on 'Date' and 'Settimana', keeping only the matching dates.\r\nmerged_df = df.join(\r\n    trend_df,\r\n    df['Date'] == trend_df['Settimana'],\r\n    how='inner'\r\n)\r\n\r\n# Select final columns\r\nmerged_df = merged_df.select(\r\n    trend_df['Settimana'].alias('data'),\r\n    round(merged_df['Weekly_Price_MA'], 2).cast(DecimalType(10, 2)).alias('prezzo'),\r\n    trend_df['interesse bitcoin'].alias('indice_google_trend').cast('int')\r\n)\r\n\r\n# Save the transformed data in Parquet format\r\nmerged_df.write.mode(\"overwrite\").parquet(\"s3://s3-sg-bucket-gold/BTC\")\r\n\r\njob.commit()"
}